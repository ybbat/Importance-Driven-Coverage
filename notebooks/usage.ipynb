{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.getcwd() + '/..')\n",
    "\n",
    "from importance_driven_coverage import attributors, clusterers, coverage\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example we are using a simple LeNet5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms.v2 as T\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(400, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2, 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2, 2)\n",
    "\n",
    "        x = x.view(-1, 16*5*5)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LeNet5().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = T.Compose([\n",
    "    T.ToImage(),\n",
    "    T.ToPureTensor(),\n",
    "    T.ToDtype(torch.float32, scale=True)\n",
    "])\n",
    "train_dataset = torchvision.datasets.MNIST(\"data\", download=True, transform=transforms, train=True)\n",
    "train, validation = data.random_split(train_dataset, [0.9, 0.1])\n",
    "train_loader = data.DataLoader(train, batch_size=128, num_workers=4)\n",
    "val_loader = data.DataLoader(validation, batch_size=128, num_workers=4)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\"data\", download=True, transform=transforms, train=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=128, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.308755 [  128/54000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.991615 [ 5504/54000]\n",
      "loss: 0.282846 [10880/54000]\n",
      "loss: 0.226823 [16256/54000]\n",
      "loss: 0.194923 [21632/54000]\n",
      "loss: 0.071484 [27008/54000]\n",
      "loss: 0.194007 [32384/54000]\n",
      "loss: 0.202465 [37760/54000]\n",
      "loss: 0.060451 [43136/54000]\n",
      "loss: 0.098882 [48512/54000]\n",
      "loss: 0.037425 [53888/54000]\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.092625 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.121083 [  128/54000]\n",
      "loss: 0.087854 [ 5504/54000]\n",
      "loss: 0.059270 [10880/54000]\n",
      "loss: 0.172158 [16256/54000]\n",
      "loss: 0.121833 [21632/54000]\n",
      "loss: 0.016013 [27008/54000]\n",
      "loss: 0.079195 [32384/54000]\n",
      "loss: 0.099693 [37760/54000]\n",
      "loss: 0.019619 [43136/54000]\n",
      "loss: 0.069155 [48512/54000]\n",
      "loss: 0.009661 [53888/54000]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.077303 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.100667 [  128/54000]\n",
      "loss: 0.037389 [ 5504/54000]\n",
      "loss: 0.050859 [10880/54000]\n",
      "loss: 0.128416 [16256/54000]\n",
      "loss: 0.115720 [21632/54000]\n",
      "loss: 0.007821 [27008/54000]\n",
      "loss: 0.061769 [32384/54000]\n",
      "loss: 0.052473 [37760/54000]\n",
      "loss: 0.016624 [43136/54000]\n",
      "loss: 0.065292 [48512/54000]\n",
      "loss: 0.008174 [53888/54000]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.061029 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=1.0, rho=0.95)\n",
    "\n",
    "def train(dataloader, model, criterion, opt):\n",
    "        size = len(dataloader.dataset)\n",
    "        num_batches = len(dataloader)\n",
    "        model.train()\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "            loss = criterion(pred, y)\n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "            if batch % (num_batches//10) == 0:\n",
    "                loss, current = loss.item(), (batch + 1) * len(X)\n",
    "                print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def val(dataloader, model, criterion):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += criterion(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "epochs = 3\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, criterion, optimizer)\n",
    "    val(val_loader, model, criterion)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDC Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to test the penultimate layer, for out model (LeNet5) this is `model.fc2`. But we want the activation values after the activation function, since the ReLU after fc2 is not available to select directly we select the next layer `model.fc3` and tell CaptumLRPAttributor and idc.calculate that we want to test the input to the selected layer. Usually it would be easier to design a model with this in mind, such that we are able to directly reference the layer we want to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ybbat/.micromamba/envs/idc/lib/python3.11/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "layer = model.fc3\n",
    "n = 6\n",
    "\n",
    "attributor = attributors.CaptumLRPAttributor(attribute_kwargs={\"attribute_to_layer_input\": True})\n",
    "clusterer = clusterers.KMeansClustererSimpleSilhouette()\n",
    "\n",
    "idc = coverage.ImportanceDrivenCoverage(model, attributor, clusterer)\n",
    "\n",
    "score, combs = idc.calculate(train_loader, test_loader, layer, n, layer_input=True,\n",
    "                           attributions_path=\"attributions.pt\",\n",
    "                           centroids_path=\"centroids.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now apply a transformation during the calculation to calculate the improvement in coverage from using this augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_trans = transforms = T.Compose([\n",
    "    T.RandAugment()\n",
    "])\n",
    "score_after, combs_after = idc.calculate(train_loader, test_loader, layer, n, transform=new_trans, layer_input=True,\n",
    "                                                   attributions_path=\"attributions.pt\",\n",
    "                                                   centroids_path=\"centroids.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total_combs attribute is populated after a calculation, it contains the set of all possible combinations of important neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idc.total_combs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the scores that the the dataset with the augmentation covers more of the important neuron combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline score:  0.3388888888888889\n",
      "score with augmentation:  0.36944444444444446\n"
     ]
    }
   ],
   "source": [
    "print(\"baseline score: \", score)\n",
    "print(\"score with augmentation: \", score_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since IDC gives us the sets of combinations that are covered, we can combine them to calculate the coverage of the baseline dataset combined with the transformed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline score 0.3388888888888889\n",
      "score with baseline+augmentation 0.38055555555555554\n"
     ]
    }
   ],
   "source": [
    "print(\"baseline score\", score)\n",
    "print(\"score with baseline+augmentation\", len(combs | combs_after)/len(idc.total_combs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
